<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.549">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Phil Chodrow">
<meta name="dcterms.date" content="2022-06-24">

<title>Ariana Mendible - The Short Story of Bregman Information for Measuring Segregation</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Ariana Mendible</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../research.html"> 
<span class="menu-text">Research</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../teaching.html"> 
<span class="menu-text">Teaching</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-projects" role="button" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Projects</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-projects">    
        <li>
    <a class="dropdown-item" href="../../../academic_projects.html">
 <span class="dropdown-text">Academic Projects</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../personal_projects.html">
 <span class="dropdown-text">Personal Projects</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../../../assets/files/cv.pdf"> 
<span class="menu-text">CV</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#the-big-picture" id="toc-the-big-picture" class="nav-link active" data-scroll-target="#the-big-picture">The Big Picture</a></li>
  <li><a href="#background" id="toc-background" class="nav-link" data-scroll-target="#background">Background</a></li>
  <li><a href="#introducing-bregman-divergences" id="toc-introducing-bregman-divergences" class="nav-link" data-scroll-target="#introducing-bregman-divergences">Introducing Bregman Divergences</a></li>
  <li><a href="#bregman-information" id="toc-bregman-information" class="nav-link" data-scroll-target="#bregman-information">Bregman Information</a>
  <ul class="collapse">
  <li><a href="#motivation-from-segregation-measurement" id="toc-motivation-from-segregation-measurement" class="nav-link" data-scroll-target="#motivation-from-segregation-measurement">Motivation From Segregation Measurement</a></li>
  <li><a href="#information-as-approximation" id="toc-information-as-approximation" class="nav-link" data-scroll-target="#information-as-approximation">Information As Approximation</a></li>
  </ul></li>
  <li><a href="#the-chain-rule" id="toc-the-chain-rule" class="nav-link" data-scroll-target="#the-chain-rule">The Chain Rule</a></li>
  <li><a href="#bregman-information-geometry" id="toc-bregman-information-geometry" class="nav-link" data-scroll-target="#bregman-information-geometry">Bregman Information Geometry</a></li>
  <li><a href="#information-geometry-and-spatial-analysis" id="toc-information-geometry-and-spatial-analysis" class="nav-link" data-scroll-target="#information-geometry-and-spatial-analysis">Information Geometry and Spatial Analysis</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">The Short Story of Bregman Information for Measuring Segregation</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Phil Chodrow </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">June 24, 2022</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<p>This is a post for folks who are interested in some of the most important mathematical properties of Bregman divergences. Bregman divergences offer a flexible platform from which to derive measures of diversity and segregation, and folks who wish to engineer such measures may benefit from understanding some useful properties.</p>
<section id="the-big-picture" class="level1">
<h1>The Big Picture</h1>
<p>A <em>Bregman divergence</em> is a measure of difference between two vectors “through the lens” of a convex function <span class="math inline">\(f\)</span>. A <em>Bregman information</em> is a measure of how variable a set of vectors is, again through the lens of <span class="math inline">\(f\)</span>. Many methods for measuring segregation from the sociology literature can be expressed simply in terms of Bregman informations. These include:</p>
<ul>
<li>The Information Theory Index of <span class="citation" data-cites="theil1971note">Thiel and Finezza (<a href="#ref-theil1971note" role="doc-biblioref">1971</a>)</span> and <span class="citation" data-cites="reardon2004measures">Reardon and O’Sullivan (<a href="#ref-reardon2004measures" role="doc-biblioref">2004</a>)</span>.</li>
<li>The Ordinal Information Theory, Variation Ratio, and Square Root Indices of <span class="citation" data-cites="reardon2009measures">Reardon (<a href="#ref-reardon2009measures" role="doc-biblioref">2009</a>)</span>.</li>
<li>The Generalized Neighborhood Sorting Index of <span class="citation" data-cites="jargowsky2005measure">Jargowsky and Kim (<a href="#ref-jargowsky2005measure" role="doc-biblioref">2005</a>)</span>.</li>
</ul>
<p>Understanding the mathematical properties of Bregman information is very helpful, in that it allows us to neatly unify the mathematical properties of each of these indices. There are two main mathematical properties of these indices that are extremely helpful in multiscale analysis.</p>
<ul>
<li><strong>Termwise interpretation</strong> (<a href="#thm-information-entropy" class="quarto-xref">Theorem&nbsp;4</a>): a Bregman information can be interpreted as a difference between a measure of local diversity and global diversity. This makes Bregman informations extremely natural as quantifications of certain concepts of segregation.</li>
<li><strong>Chain rule</strong> (<a href="#thm-chain-rule" class="quarto-xref">Theorem&nbsp;5</a>): when coarse-graining data, a Bregman information decomposes into terms corresponding to the information contained in the coarse-graining and the information left over. This makes Bregman informations extremely amenable to multiscale spatial analysis, and allows them to quantify the significance of spatial boundaries in separating groups with different demographic features.</li>
</ul>
<p>Additionally, Bregman informations are related to <em>information geometries</em>, which turn out to be one useful route for incorporating space into our analytical toolbox. In particular, the Bregman information can be used to quantify how quickly demographics shift in space. This turns out to be because they are related to the curvature of a so-called <em>information manifold</em>. We won’t discuss this point too much here, but there’s much more discussion in <span class="citation" data-cites="chodrow2017structure">Chodrow (<a href="#ref-chodrow2017structure" role="doc-biblioref">2017b</a>)</span>.</p>
</section>
<section id="background" class="level1">
<h1>Background</h1>
<p>The primary audience for these notes consists of folks with training in math and/or machine learning theory. I’ll assume familiarity with:</p>
<ul>
<li>The gradient operator <span class="math inline">\(\nabla\)</span>.</li>
<li>Joint, marginal, and conditional probability distributions on discrete sets.</li>
<li><a href="https://en.wikipedia.org/wiki/Convex_function">Convex functions</a>.</li>
<li>Prior background in <a href="https://en.wikipedia.org/wiki/Information_theory#:~:text=Information%20theory%20is%20the%20scientific,Claude%20Shannon%20in%20the%201940s.">Shannon information theory</a> is helpful but not assumed. I tell this story in my preferred sequence in <span class="citation" data-cites="chodrow2017divergence">Chodrow (<a href="#ref-chodrow2017divergence" role="doc-biblioref">2017a</a>)</span>.</li>
</ul>
</section>
<section id="introducing-bregman-divergences" class="level1 page-columns page-full">
<h1>Introducing Bregman Divergences</h1>
<div class="callout callout-style-simple callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Bregman Divergence
</div>
</div>
<div class="callout-body-container callout-body">
<p>Let <span class="math inline">\(\mathcal{P}\subseteq \mathbb{R}^n\)</span> be a <a href="https://en.wikipedia.org/wiki/Convex_set">convex set</a>. Let <span class="math inline">\(f:\mathcal{P}\rightarrow \mathbb{R}\)</span> be a continuously differentiable and <a href="https://en.wikipedia.org/wiki/Convex_function">convex function</a>. Then, the <em>Bregman divergence</em> induced by <span class="math inline">\(f\)</span> on <span class="math inline">\(\mathcal{P}\)</span> is the function <span class="math inline">\(d_f:\mathcal{P}^2 \rightarrow \mathbb{R}\)</span> given by</p>
<p><span class="math display">\[
d_f(p,q) = f(p) - f(q) - \langle \nabla f(q), p-q \rangle\;.
\]</span></p>
</div>
</div>
<div class="page-columns page-full"><p> You can think of <span class="math inline">\(d_f\)</span> as a function that compares the two elements <span class="math inline">\(p\)</span> and <span class="math inline">\(q\)</span> of <span class="math inline">\(\mathcal{P}\)</span>. Bregman divergences are not distances, but they do have some similar properties. Here are some of them:</p><div class="no-row-height column-margin column-container"><span class="margin-aside">Some more detail on <a href="https://en.wikipedia.org/wiki/Bregman_divergence">Wikipedia</a>.</span></div></div>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="thm-bregman-basics" class="theorem">
<p><span class="theorem-title"><strong>Theorem 1 (Fundamental Properties of Bregman Divergences)</strong></span> For any continuously differentiable and convex <span class="math inline">\(f\)</span>:</p>
<ul>
<li><span class="math inline">\(d_f(p, p) = 0\)</span> for all <span class="math inline">\(p \in \mathcal{P}\)</span>.</li>
<li><span class="math inline">\(d_f(p,q) \geq 0\)</span> for all <span class="math inline">\(p, q \in \mathcal{P}\)</span>.</li>
<li>If <span class="math inline">\(f\)</span> is strictly convex, then <span class="math inline">\(d_f(p,q) = 0\)</span> iff <span class="math inline">\(p = q\)</span>.</li>
</ul>
<p>On the other hand, <span class="math inline">\(d_f(p, q) \neq d_f(q,p)\)</span> in general, and there is no triangle inequality.</p>
</div>
</div>
</div>
</div>
<p><a href="#thm-bregman-basics" class="quarto-xref">Theorem&nbsp;1</a> tells us that we can think of <span class="math inline">\(d_f\)</span> as a comparison operator, but it is important to remember that it is <strong>not</strong> in general a metric on <span class="math inline">\(\mathcal{P}\)</span>. Proofs for <a href="#thm-bregman-basics" class="quarto-xref">Theorem&nbsp;1</a> are outlined on <a href="https://en.wikipedia.org/wiki/Bregman_divergence">Wikipedia</a>.</p>
<div class="callout callout-style-simple callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Examples of Bregman Divergences
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li>Let <span class="math inline">\(\mathcal{X}\)</span> be a finite set with <span class="math inline">\(\left|\mathcal{X}\right| = n\)</span>. Let <span class="math inline">\(\mathcal{P}_\mathcal{X}\)</span> be the set of all discrete probability distributions over the elements of <span class="math inline">\(\mathcal{X}\)</span>. Let <span class="math inline">\(f(p) = \sum_{x \in \mathcal{X}} p(x) \log p(x)\)</span>. Then, <span class="math inline">\(d_f\)</span> is the <em>Kullback-Leibler divergence</em>, given by <span class="math display">\[
d_f(p,q) = \sum_{x \in \mathcal{X}} p(x) \log \frac{p(x)}{q(x)}\;.
\]</span> This follows a direct calculation of the gradient <span class="math inline">\(\nabla f\)</span> and subsequent simplification.<br>
</li>
<li>Let <span class="math inline">\(\mathcal{P}= \mathbb{R}^n\)</span> and let <span class="math inline">\(f(x) = \lVert x \rVert^2\)</span>, the squared Euclidean norm. Then, <span class="math inline">\(d_f\)</span> is the squared Euclidean distance: <span class="math display">\[
d_f(x, y) = \lVert x - y \rVert^2\;.
\]</span></li>
</ol>
</div>
</div>
</section>
<section id="bregman-information" class="level1 page-columns page-full">
<h1>Bregman Information</h1>
<section id="motivation-from-segregation-measurement" class="level2">
<h2 class="anchored" data-anchor-id="motivation-from-segregation-measurement">Motivation From Segregation Measurement</h2>
<p>What does it mean to say that a city, for example, is segregated by class? One natural image is of a city separated by a line, with high-wealth individuals on one side and low-wealth individuals on another. One framing of this situation is in terms of information and correlation:</p>
<ul>
<li>Knowing <em>where someone lives</em> makes you more able to guess <em>their wealth</em>. (“They live on the east side, have you seen those houses?”)</li>
<li>Knowing <em>someone’s wealth</em> makes you more able to guess <em>where they live</em>. (“Folks with that salary tend to settle on the east side.”)</li>
</ul>
<p>The concept of Bregman information can be used to make precise what it means for one attribute (like a residential location) to give information about another attribute (like wealth).</p>
</section>
<section id="information-as-approximation" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="information-as-approximation">Information As Approximation</h2>
<p>Let <span class="math inline">\(\mathcal{X}\)</span> and <span class="math inline">\(\mathcal{Y}\)</span> be two finite sets. Let <span class="math inline">\(p_{XY}\)</span> be a probability distribution on <span class="math inline">\(\mathcal{X}\times \mathcal{Y}\)</span>. That is, if I pick a random object from <span class="math inline">\(\mathcal{X}\times \mathcal{Y}\)</span>, the probability that this object has property <span class="math inline">\(x \in \mathcal{X}\)</span> and <span class="math inline">\(y \in \mathcal{Y}\)</span> is <span class="math inline">\(p_{XY}(x,y)\)</span>. Concretely, think of <span class="math inline">\(X\)</span> as being a demographic feature like wealth and <span class="math inline">\(Y\)</span> as being a spatial location. Then, <span class="math inline">\(p_{XY}(\text{high wealth}, \mathrm{Providence})\)</span> is the fraction of all people who have high wealth and live in Providence. We’ll develop an information measure to quantify the extent to which <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are dependent or correlated. I’ll treat the extent of dependence or correlation as an operating definition of “demographic spatial segregation.”</p>
<div class="page-columns page-full"><p>We develop the idea of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> as being dependent by considering the conditional distributions <span class="math inline">\(p_{X|y}(x) = \frac{p_{XY}(x,y)}{p_Y(y)}\)</span>.  Here, <span class="math inline">\(p_Y(y) = \sum_{x\in \mathcal{X}} p_{XY}(x,y)\)</span> is the marginal distribution of <span class="math inline">\(Y\)</span>. You can think of <span class="math inline">\(p_{X|y}(x)\)</span> as the probability that an individual in location <span class="math inline">\(y\)</span> has demographic attribute <span class="math inline">\(x\)</span>. The distribution <span class="math inline">\(p_{X|y}\)</span> is an element of <span class="math inline">\(\mathcal{P}_{\mathcal{X}}\)</span>, the set of probability distributions over <span class="math inline">\(\mathcal{X}\)</span>. We have one of those distributions for each possible choice of <span class="math inline">\(y \in \mathcal{Y}\)</span>. If these distributions are very different – if they depend strongly on the choice of <span class="math inline">\(y\)</span> – then knowing <span class="math inline">\(y\)</span> would make a big difference in what we know about <span class="math inline">\(x\)</span>. We would say that <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are highly dependent. How do we measure how different the collection of distributions <span class="math inline">\(\{p_{X|y}\}\)</span> is? A standard, two-step approach is:</p><div class="no-row-height column-margin column-container"><span class="margin-aside">The notation <span class="math inline">\(p_{X|y}(x)\)</span> is nonstandard, and is chosen to make some later calculations a bit more compact.</span></div></div>
<ol type="1">
<li>First, find a point <span class="math inline">\(\bar{p}_X\)</span> that best approximates all the marginal distributions <span class="math inline">\(p_{X|y}\)</span>.</li>
<li>Compute the average divergence of the conditionals to <span class="math inline">\(\bar{p}_X\)</span>. This average is <span class="math display">\[
I_f(X:Y;\bar{p}_X) = \sum_{y \in \mathcal{Y}} p_Y(y) d_f(p_{X|y}, \bar{p}_X)
\]</span> This is a gnarly expression, but you can think of as expressing: on average, how far (in the sense of divergence <span class="math inline">\(d_f\)</span>) is a typical local distribution <span class="math inline">\(p_{X|y}\)</span> from its approximator <span class="math inline">\(\bar{p}_X\)</span>? If the answer is small, then we know that all the local distributions aren’t <em>too far</em> from their approximators, and therefore shouldn’t be <em>too far</em> from each other, either.</li>
</ol>
<p>As it turns out, there’s a correct choice of <span class="math inline">\(\bar{p}_X\)</span>. This result is Proposition 1 of <span class="citation" data-cites="banerjee2005clustering">Banerjee et al. (<a href="#ref-banerjee2005clustering" role="doc-biblioref">2005</a>)</span>.</p>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="thm-mean-minimizer" class="theorem">
<p><span class="theorem-title"><strong>Theorem 2 (Mean is a Minimizer)</strong></span> For any Bregman divergence, the smallest value of <span class="math inline">\(I_f(X:Y;\bar{p}_X)\)</span> is attained when <span class="math inline">\(\bar{p}_X = p_X\)</span>, the marginal distribution of <span class="math inline">\(X\)</span>. This distribution is given by <span class="math inline">\(p_X(x) = \sum_{y \in Y}p_{XY}(x,y)\)</span>. More formally,</p>
<p><span class="math display">\[
\mathop{\mathrm{argmin\;}}_{\bar{p}_X} I_f(X:Y;\bar{p}_X) = p_X\;.
\]</span></p>
</div>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Bregman Information
</div>
</div>
<div class="callout-body-container callout-body">
<p>We will use the abbreviation <span class="math inline">\(I_f(X: Y) = I_f(X:Y;p_X)\)</span> for the minimizing value of <span class="math inline">\(I_f(X:Y;\bar{p}_X)\)</span>. We call <span class="math inline">\(I_f(X:Y)\)</span> the <strong>Bregman information</strong> in <span class="math inline">\(Y\)</span> about <span class="math inline">\(X\)</span>.</p>
</div>
</div>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="thm-independence" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3 (Bregman Information and Independence)</strong></span> Let <span class="math inline">\(f\)</span> be strictly convex and let <span class="math inline">\(p_Y(y) &gt; 0\)</span> for all <span class="math inline">\(y \in \mathcal{Y}\)</span>. Then, <span class="math inline">\(I_f(X:Y) = 0\)</span> if and only if <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are independent random variables.</p>
</div>
</div>
</div>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>Recall that <span class="math inline">\(I_f(X:Y) = \sum_{y \in \mathcal{Y}} p_Y(y) d_f(p_{X|y}, p_X)\)</span>. Since <span class="math inline">\(p_Y(y) &gt; 0\)</span> for each <span class="math inline">\(y \in \mathcal{Y}\)</span> by hypothesis, for <span class="math inline">\(I_f(X:Y) = 0\)</span> we must have <span class="math inline">\(d_f(p_{X|y}, p_X)\)</span> for each <span class="math inline">\(y\)</span>. If <span class="math inline">\(f\)</span> is strictly convex, then by <a href="#thm-bregman-basics" class="quarto-xref">Theorem&nbsp;1</a>, <span class="math inline">\(d_f(p,q) = 0\)</span> iff <span class="math inline">\(p = q\)</span>. So, we must have <span class="math inline">\(p_{X|y} = p_X\)</span> for each <span class="math inline">\(y\)</span>, which implies that <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are independent.</p>
</div>
<p>There is another formula for the Bregman information that helps to interpret its meaning. This formula is the version emphasized in <a href="../../../posts/2022-06-16-info-segregation-2.qmd">this post</a>, which expresses global diversity as a sum of local diversity and global segregation.</p>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="thm-information-entropy" class="theorem">
<p><span class="theorem-title"><strong>Theorem 4</strong></span> The Bregman information satisfies</p>
<p><span class="math display">\[
I_f(X:Y) = \sum_{y \in \mathcal{Y}} p_Y(y) f(p_{X|y}) - f(p_X)\;.
\]</span></p>
</div>
</div>
</div>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>We can directly write out <span class="math display">\[
\begin{aligned}
    I_f(X:Y) &amp;= \sum_{y \in \mathcal{Y}} p_Y(y) d_f(p_{X|y}, p_X) \\
             &amp;= \sum_{y \in \mathcal{Y}} p_Y(y) \left[f(p_{X|y}) - f(p_X) - \langle \nabla f(p_X), p_{X|y} - p_X\rangle \right] \\
\end{aligned}
\]</span> Next, we use that <span class="math inline">\(\sum_{y \in \mathcal{Y}} p_Y(y) p_X = \sum_{y \in \mathcal{Y}} p_Y(y) p_{X|y} = p_X\)</span>, which causes the inner product to vanish. The only remaining terms are <span class="math display">\[
I_f(X:Y) = \sum_{y \in \mathcal{Y}} p_Y(y) f(p_{X|y}) - f(p_X)\;,
\]</span> completing the proof.</p>
</div>
<p><a href="#thm-information-entropy" class="quarto-xref">Theorem&nbsp;4</a> is often used as the definition of the mutual information in the context of Shannon information theory; indeed, it’s the definition that I emphasize in my <a href="../../../posts/2022-06-16-info-segregation-2.qmd">previous post</a> on Shannon information theory. The interpretation of this theorem as relating global segregation, global diversity, and local diversity translates directly.</p>
</section>
</section>
<section id="the-chain-rule" class="level1 page-columns page-full">
<h1>The Chain Rule</h1>
<div class="page-columns page-full"><p>From a practical perspective, one of the most important properties of the Bregman information is the chain rule. We’ll now state and prove it. </p><div class="no-row-height column-margin column-container"><span class="margin-aside">This result is a rewording of Theorem 1 in <span class="citation" data-cites="banerjee2005clustering">Banerjee et al. (<a href="#ref-banerjee2005clustering" role="doc-biblioref">2005</a>)</span>.</span></div></div>
<p>Let <span class="math inline">\(\mathcal{Z}\)</span> be a finite set, and let <span class="math inline">\(g: \mathcal{Y}\rightarrow \mathcal{Z}\)</span>. Let <span class="math inline">\(Z = g(Y)\)</span>. We write <span class="math inline">\(p_{X|z}(x) = \frac{\sum_{Y \in g^{-1}(z)} p_{XY}(x,y)}{\sum_{Y \in g^{-1}(z)} p_Y(y)}\)</span> for the distribution of <span class="math inline">\(X\)</span> conditioned on the event <span class="math inline">\(Z = z\)</span>. We similarly write <span class="math inline">\(p_{Y|z}\)</span> for the distribution of <span class="math inline">\(y\)</span> conditioned on <span class="math inline">\(Z = z\)</span>.</p>
<div class="callout callout-style-simple callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Conditional Bregman Information
</div>
</div>
<div class="callout-body-container callout-body">
<p>The <strong>conditional Bregman information in <span class="math inline">\(Y\)</span> about <span class="math inline">\(X\)</span> given <span class="math inline">\(Z\)</span></strong>, written <span class="math inline">\(I(X:Y|Z)\)</span>, is <span class="math display">\[
I(X:Y|Z) = \sum_{z \in Z} p_Z(z) I_f(X:Y|z) = \sum_{z \in \mathcal{Z}} p_Z(z) \sum_{y \in \mathcal{Y}}p_{Y|z}(y) d_f(p_{X|y}, p_{X|z})\;.
\]</span></p>
</div>
</div>
<p>You can think of <span class="math inline">\(I_f(X:Y|z)\)</span> as the information that <span class="math inline">\(Y\)</span> contains about <span class="math inline">\(X\)</span> in a world in which <span class="math inline">\(g(Y)\)</span> is always equal to <span class="math inline">\(z\)</span>. The conditional information <span class="math inline">\(I(X:Y|Z)\)</span> is the average across values of <span class="math inline">\(z\)</span>.</p>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="thm-chain-rule" class="theorem">
<p><span class="theorem-title"><strong>Theorem 5 (Chain Rule of Bregman Information)</strong></span> If <span class="math inline">\(Z = g(Y)\)</span> for some function <span class="math inline">\(g\)</span>, then</p>
<p><span class="math display">\[
I_f(X:Y) = I_f(X:Z) + I_f(X:Y|Z)
\]</span></p>
</div>
</div>
</div>
</div>
<div class="proof page-columns page-full">
<p><span class="proof-title"><em>Proof</em>. </span>We’ll start by writing</p>
<p><span class="math display">\[
\begin{aligned}
I_f(X:Y) &amp;= \sum_{y \in \mathcal{Y}} p_Y(y) d_f(p_{X|y}, p_X) \\
         &amp;= \sum_{z \in \mathcal{Z}} \sum_{y \in g^{-1}(z)} p_Y(y) d_f(p_{X|y}, p_X) \\
         &amp;= \sum_{z \in \mathcal{Z}} \sum_{y \in g^{-1}(z)} p_Y(y) \left[d_f(p_{X|y}, p_{X|z}) + d_f(p_{X|z}, p_X) + \langle  \nabla f(p_{X|z}) - \nabla f(p_X),  p_{X|y} - p_{X|z}\rangle \right]
\end{aligned}
\]</span></p>
<div class="page-columns page-full"><p>This last line is the “law of cosines” for Bregman divergences and follows by just rearranging some terms. Let’s break this final line down into three terms.</p><div class="no-row-height column-margin column-container"><span class="margin-aside">See <a href="https://en.wikipedia.org/wiki/Bregman_divergence#Properties">Wikipedia</a></span></div></div>
<p>First,</p>
<p><span class="math display">\[
\begin{aligned}
\sum_{z \in \mathcal{Z}} \sum_{y \in g^{-1}(z)} p_Y(y) d_f(p_{X|y}, p_{X|z})
&amp;= \sum_{z \in \mathcal{Z}} p_{Z}(z) \sum_{y \in g^{-1}(z)} \frac{p_Y(y)}{p_Z(z)} d_f(p_{X|y}, p_{X|z}) \\
&amp;= \sum_{z \in \mathcal{Z}} p_{Z}(z) \sum_{y \in g^{-1}(z)} p_{Y|z}(y) d_f(p_{X|y}, p_{X|z}) \\
&amp;= I_f(X:Y|Z)\;.
\end{aligned}
\]</span></p>
<p>Second,</p>
<p><span class="math display">\[
\begin{aligned}
\sum_{z \in \mathcal{Z}} \sum_{y \in g^{-1}(z)} p_Y(y)d_f(p_{X|z}, p_X) = \sum_{z \in \mathcal{Z}} p_Z(z)d_f(p_{X|z}, p_X) = I_f(X:Z)\;.
\end{aligned}
\]</span></p>
<p>Third and finally, the very last term is equal to 0 because</p>
<p><span class="math display">\[
\begin{aligned}
\sum_{y \in g^{-1}(z)}p_Y(y)p_{X|y}(x) = p_{X|z}(x)\;.
\end{aligned}
\]</span> for all <span class="math inline">\(x\)</span>.</p>
<p>So, we have shown that <span class="math inline">\(I_f(X:Y) = I_f(X:Z) + I_f(X:Y|Z)\)</span>, completing the proof.</p>
</div>
<p>You can think of the chain rule as saying the following:</p>
<blockquote class="blockquote">
<p>The information in <span class="math inline">\(Y\)</span> about <span class="math inline">\(X\)</span> is equal to the information that <span class="math inline">\(Z\)</span> holds about <span class="math inline">\(X\)</span>, plus the <em>additional</em> information that <span class="math inline">\(Y\)</span> holds in a world in which you already know <span class="math inline">\(Z\)</span>.</p>
</blockquote>
</section>
<section id="bregman-information-geometry" class="level1 page-columns page-full">
<h1>Bregman Information Geometry</h1>
<p>A Bregman divergence is not a metric. <a href="#thm-bregman-basics" class="quarto-xref">Theorem&nbsp;1</a> highlights some ways in which a Bregman divergence is like a metric. There is, however, another important way. In brief, Bregman divergences between “nearby” vectors behave like <em><a href="https://en.wikipedia.org/wiki/Riemannian_geometry">Riemannian metrics</a></em>, and therefore allow us to do geometry. Here’s a concrete version of this idea:</p>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="thm-riemannian" class="theorem">
<p><span class="theorem-title"><strong>Theorem 6</strong></span> The Hessian (matrix of second derivatives) <span class="math inline">\(H(q)\)</span> of <span class="math inline">\(f\)</span> at point <span class="math inline">\(q\)</span> is positive semi-definite for any <span class="math inline">\(q\)</span>, and positive-definite if <span class="math inline">\(f\)</span> is strictly convex. Furthermore, there exists <span class="math inline">\(\epsilon &gt; 0\)</span> such that, if <span class="math inline">\(\lVert p - q \rVert &lt; \epsilon\)</span>, then <span class="math display">\[
d_f(p, q) = \frac{1}{2} \langle p-q,H(q)(p-q) \rangle + O(\epsilon^2)
\]</span></p>
</div>
</div>
</div>
</div>
<div class="proof page-columns page-full">
<div class="page-columns page-full"><p><span class="proof-title"><em>Proof</em>. </span>Positive (semi)-definiteness of <span class="math inline">\(H(q)\)</span> follows from standard results about the Hessians of convex functions.  To prove the equation, we Taylor-expand <span class="math inline">\(d_f(p, q)\)</span> in the first argument around the point <span class="math inline">\(q\)</span>, which we can do in an <span class="math inline">\(\epsilon\)</span>-neighborhood for <span class="math inline">\(\epsilon\)</span> chosen sufficiently small.</p><div class="no-row-height column-margin column-container"><span class="margin-aside">See e.g.&nbsp;<a href="https://cims.nyu.edu/~cfgranda/pages/OBDA_fall17/notes/convex_optimization.pdf">these notes</a>, Cor. 2.18 and Remark 2.19</span></div></div>
<p><span class="math display">\[
d_f(p, q) = d_f(q, q) + \langle \nabla_1 d_f(q, q),p - q \rangle + \frac{1}{2} \langle p-q, \bar{H}(p-q)\rangle + O(\lVert p - q \rVert^2)\;.
\]</span></p>
<p>Here, <span class="math inline">\(\nabla_1 d_f(q, q)\)</span> indicates that derivatives are taken only in the first argument of <span class="math inline">\(d_f\)</span>. <span class="math inline">\(\bar{H}\)</span> is the Hessian matrix of <span class="math inline">\(d_f\)</span>, again with derivatives taken only in the first argument.</p>
<p>Let’s evaluate terms. We have <span class="math inline">\(d_f(p, p) = 0\)</span> by <a href="#thm-bregman-basics" class="quarto-xref">Theorem&nbsp;1</a>. Moving to the second term, we have <span class="math display">\[
\begin{aligned}
\langle \nabla_1 d_f(q, q), p-q \rangle = \langle \nabla f(q) -  \nabla f(q), p-q \rangle \rangle  = 0
\end{aligned}
\]</span></p>
<p>It remains to calculate <span class="math inline">\(\bar{H}\)</span>. When taking two derivatives with respect to the first argument of <span class="math inline">\(d_f\)</span>, only the term initially corresponding to <span class="math inline">\(f(p)\)</span> survives, and we therefore have <span class="math inline">\(\bar{H} = H\)</span>, the Hessian of <span class="math inline">\(H\)</span>. Finally, noting that <span class="math inline">\(\lVert p - q \rVert &lt; \epsilon\)</span> by construction completes the argument.</p>
</div>
<p>One reason that <a href="#thm-riemannian" class="quarto-xref">Theorem&nbsp;6</a> is so good is that it allows us actually get “real” metrics from divergences. From the simplest perspective, we know that, for <span class="math inline">\(p\)</span> and <span class="math inline">\(q\)</span> close, <span class="math inline">\(d_f(p,q) \approx \frac{1}{2} \langle p-q,H(q)(p-q)\rangle\)</span>, which is a metric when <span class="math inline">\(f\)</span> is strictly convex (as <span class="math inline">\(H\)</span> is then positive-definite). On the other hand, we can also use the perspective of Riemannian geometry, under which <span class="math inline">\(H\)</span> plays the role of an <em>ambient metric tensor</em>. Many problems in statistical inference can be framed in terms exploring the structure of a <em>manifold</em> of probability distributions. Any smooth parameterized family of distributions defines such a manifold; for example, the Poisson distribution <span class="math inline">\(p_K(k;\lambda) = \frac{e^{\lambda}\lambda^k}{k!}\)</span> is parameterized by a single parameter <span class="math inline">\(\lambda\)</span>. We can compare these distributions using the ambient metric, and the result is a <em>Riemannian metric</em> induced on the 1-dimensional manifold of distributions.</p>
<p>For more on information geometry, see <span class="citation" data-cites="nielsen2020elementary">Nielsen (<a href="#ref-nielsen2020elementary" role="doc-biblioref">2020</a>)</span> or <span class="citation" data-cites="amari2016information">Amari (<a href="#ref-amari2016information" role="doc-biblioref">2016</a>)</span>.</p>
</section>
<section id="information-geometry-and-spatial-analysis" class="level1">
<h1>Information Geometry and Spatial Analysis</h1>
<p>The information geometry point can feel pretty abstract, but there’s a specific reason to be interested in this perspective when studying spatial segregation. In particular, consider the following idealized model of Census data. Let <span class="math inline">\(S\)</span> be a connected, closed region in <span class="math inline">\(\mathbb{R}^2\)</span>. For each point <span class="math inline">\(s \in S\)</span>, we have a probability distribution <span class="math inline">\(p_{X|s}\)</span> over some set of demographic variables <span class="math inline">\(\mathcal{X}\)</span>.</p>
<p>We now impose the assumption that <span class="math inline">\(p_{X|s}\)</span> is smooth as a function of <span class="math inline">\(s\)</span>. This allows us to apply <a href="#thm-riemannian" class="quarto-xref">Theorem&nbsp;6</a>, which in turn allows us to treat <span class="math inline">\(S\)</span> as a Riemannian manifold and do geometric calculations in a metric that is adapted to the demographic structure. This allow us to do things like measure “demographic distance” between points in space, and also enables some novel approaches to characterizing the spatial scale of segregation <span class="citation" data-cites="chodrow2017structure">(<a href="#ref-chodrow2017structure" role="doc-biblioref">Chodrow 2017b</a>)</span>.</p>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-amari2016information" class="csl-entry" role="listitem">
Amari, Shun-ichi. 2016. <em>Information Geometry and Its Applications</em>. Vol. 194. Springer.
</div>
<div id="ref-banerjee2005clustering" class="csl-entry" role="listitem">
Banerjee, Arindam, Srujana Merugu, Inderjit S Dhillon, Joydeep Ghosh, and John Lafferty. 2005. <span>“Clustering with Bregman Divergences.”</span> <em>Journal of Machine Learning Research</em> 6 (10).
</div>
<div id="ref-chodrow2017divergence" class="csl-entry" role="listitem">
Chodrow, Philip. 2017a. <span>“Divergence, Entropy, Information: An Opinionated Introduction to Information Theory.”</span> <em>arXiv Preprint arXiv:1708.07459</em>.
</div>
<div id="ref-chodrow2017structure" class="csl-entry" role="listitem">
———. 2017b. <span>“Structure and Information in Spatial Segregation.”</span> <em>Proceedings of the National Academy of Sciences</em> 114 (44): 11591–96.
</div>
<div id="ref-jargowsky2005measure" class="csl-entry" role="listitem">
Jargowsky, Paul A, and Jeongdai Kim. 2005. <span>“A Measure of Spatial Segregation: The Generalized Neighborhood Sorting Index.”</span> <em>University of Texas, Dallas</em>.
</div>
<div id="ref-nielsen2020elementary" class="csl-entry" role="listitem">
Nielsen, Frank. 2020. <span>“An Elementary Introduction to Information Geometry.”</span> <em>Entropy</em> 22 (10): 1100.
</div>
<div id="ref-reardon2009measures" class="csl-entry" role="listitem">
Reardon, Sean F. 2009. <span>“Measures of Ordinal Segregation.”</span> In <em>Occupational and Residential Segregation</em>. Emerald Group Publishing Limited.
</div>
<div id="ref-reardon2004measures" class="csl-entry" role="listitem">
Reardon, Sean F, and David O’Sullivan. 2004. <span>“Measures of Spatial Segregation.”</span> <em>Sociological Methodology</em> 34 (1): 121–62.
</div>
<div id="ref-theil1971note" class="csl-entry" role="listitem">
Thiel, Henri, and Anthony Finezza. 1971. <span>“A Note on the Measurement of Racial Integration of Schools by Means of Informational Concepts.”</span> <em>Journal of Mathematical Sociology</em> 1: 187–94.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>